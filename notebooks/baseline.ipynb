{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0599d14",
   "metadata": {},
   "source": [
    "# Baseline Experiment - Sentiment Analysis\n",
    "## Model: FinBERT PT-BR\n",
    "- Hypothesis (h1a): Sentiment outputs, mapped to direction, can predict short-term exchange rate movements.\n",
    "- Objective: A baseline comparison before testing hyped-up LLMs capabilities\n",
    "- Value Proposition: This is the first known study to be conducted on applying language models to trade in emerging currency markets. Especially in a multilingual context.\n",
    "- Why sentiment analysis as baseline: \n",
    "    - FinBERT is widely cited in financial NLP literature\n",
    "    - outperforms general BERT and lexicon-based models on tasks like financial sentiment classification\n",
    "    - Traditional ML methods rely on sparse inputs or static word embeddings (like Word2Vec) which don't capture context\n",
    "    - sentiment analysis is commonly used in generating trading signals, however I believe that market does not operate\n",
    "    on whether a piece of text is happy or sad. Thus, I'm expecting the following experiments to outperform this baseline. \n",
    "    I just want to rule sentiment analysis out of the picture. \"Predicting directional movement\" is a better approach.\n",
    "    - it was used as a benchmark in very similar paper found at https://doi.org/10.1016/j.mlwa.2023.100508\n",
    "\n",
    "- Independent Variable (Predictor):\n",
    "    - Text: headline / article content\n",
    "    - Category: FinBERT sentiment output\n",
    "    - Binary Label: heuristic mapping (positive -> 1, negative -> -1) (bullish or bearish in commercial terms)\n",
    "    - (POSSIBLY CONSIDER as a control var/experiment?): Multi-class Label: neutral (0) label defined by threshold label (min exchange rate % change)\n",
    "\n",
    "- Dependent Variable (Ground Truth):\n",
    "    - Directional Movement: binary direction of exchange rate following news timestamp (time frame TBD)\n",
    "    - (POSSIBLY CONSIDER?): percent change in exchange rate over defined window? Measures profitability...\n",
    "\n",
    "- Dataset Creation Process:\n",
    "    - News Data: 4630 financial news headlines (some with articles, double checked that number) with precise timestamps, in Brazilian-Portuguese\n",
    "        - Bom Dia Mercado (BDM) → Eli formatted news data into excel file → preprocess.ipynb → export to repo → final dataset\n",
    "    - FX Rate Data: Minute-level time series of USD/BRL exchange rates, synchronized with news timestamps.\n",
    "        - Bloomberg → retrieve USD/BRL exchange rates as excel file → preprocess.ipynb → export to repo → final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb17833",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For FINBERT BASELINE only use HEADLINES not ARTICLE CONTENT and COMMENTS \n",
    "'''\n",
    "\n",
    "# Step 1: Load processed data and drop unnecessary columns\n",
    "import pandas as pd\n",
    "allen_df = pd.read_csv('../data/processed/allen-corpus.csv')\n",
    "fx_df = pd.read_csv('../data/processed/usd-brl.csv')\n",
    "\n",
    "# Drop 'ARTICLE CONTENT' and 'COMMENTS' columns if they exist\n",
    "for col in ['ARTICLE CONTENT', 'COMMENTS']:\n",
    "    if col in allen_df.columns:\n",
    "        allen_df = allen_df.drop(columns=[col])\n",
    "\n",
    "# Preview data\n",
    "display(allen_df.head())\n",
    "display(fx_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b5b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 & 3: Match exchange rates and label ground truth for t+1 to t+20 minutes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Ensure timestamps are datetime\n",
    "allen_df['Timestamp'] = pd.to_datetime(allen_df['Timestamp'])\n",
    "fx_df['Timestamp'] = pd.to_datetime(fx_df['Timestamp'])\n",
    "\n",
    "# Convert fx_times to numpy datetime64 for searchsorted\n",
    "fx_times = fx_df['Timestamp'].values.astype('datetime64[ns]')\n",
    "fx_rates = fx_df['USD/BRL'].values\n",
    "\n",
    "# Helper: find closest fx rate at a given time\n",
    "def get_closest_rate(ts, fx_times, fx_rates):\n",
    "    # Convert ts to numpy datetime64 if it's a pandas Timestamp\n",
    "    ts64 = np.datetime64(ts)\n",
    "    idx = np.searchsorted(fx_times, ts64)\n",
    "    if idx == 0:\n",
    "        return fx_rates[0]\n",
    "    if idx == len(fx_times):\n",
    "        return fx_rates[-1]\n",
    "    before = fx_times[idx-1]\n",
    "    after = fx_times[idx]\n",
    "    if abs((ts64 - before).astype('timedelta64[s]').astype(int)) <= abs((after - ts64).astype('timedelta64[s]').astype(int)):\n",
    "        return fx_rates[idx-1]\n",
    "    else:\n",
    "        return fx_rates[idx]\n",
    "\n",
    "# For each news, get fx at t and at t+1 to t+20 minutes\n",
    "allen_df['fx_t'] = allen_df['Timestamp'].apply(lambda t: get_closest_rate(t, fx_times, fx_rates))\n",
    "for n in range(1, 21):\n",
    "    allen_df[f'fx_t+{n}'] = allen_df['Timestamp'].apply(lambda t: get_closest_rate(t + pd.Timedelta(minutes=n), fx_times, fx_rates))\n",
    "    allen_df[f'direction_gt_{n}'] = np.where(allen_df[f'fx_t+{n}'] > allen_df['fx_t'], 1, -1)\n",
    "\n",
    "# Show a preview of the new columns\n",
    "cols = ['Timestamp','fx_t'] + [f'fx_t+{n}' for n in range(1, 6)] + [f'direction_gt_{n}' for n in range(1, 6)]\n",
    "allen_df[cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f9200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Prepare text data for FinBERT-PT-BR (headlines only)\n",
    "# At this point, only the 'HEADING' column remains for text input\n",
    "allen_df['text'] = allen_df['HEADING'].astype(str).str.strip()\n",
    "\n",
    "allen_df[['text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb6db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Run FinBERT-PT-BR sentiment analysis (binary only)\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "model_name = 'lucas-leme/FinBERT-PT-BR'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Set up pipeline (ignore neutral, only positive/negative)\n",
    "sentiment_pipe = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer, truncation=True, max_length=256)\n",
    "\n",
    "def map_sentiment(result):\n",
    "    label = result['label'].lower()\n",
    "    if 'positive' in label:\n",
    "        return 1\n",
    "    elif 'negative' in label:\n",
    "        return -1\n",
    "    else:\n",
    "        return None  # ignore neutral or unknown\n",
    "\n",
    "# Run sentiment prediction\n",
    "allen_df['sentiment_pred'] = allen_df['text'].apply(lambda x: map_sentiment(sentiment_pipe(x)[0]))\n",
    "\n",
    "allen_df[['text','sentiment_pred']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f099e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate predictions vs ground truth for t+1 to t+20 minutes\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Drop rows where sentiment_pred is None (i.e., neutral or missing)\n",
    "eval_df = allen_df.dropna(subset=['sentiment_pred'])\n",
    "\n",
    "horizons = [(f'direction_gt_{i}', f'{i} min') for i in range(1, 21)]\n",
    "\n",
    "fig, axes = plt.subplots(4, 5, figsize=(24, 16))\n",
    "accuracies = []\n",
    "for idx, (col, label) in enumerate(horizons):\n",
    "    row, col_idx = divmod(idx, 5)\n",
    "    y_true = eval_df[col] if col in eval_df else None\n",
    "    y_pred = eval_df['sentiment_pred']\n",
    "    if y_true is not None:\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=[1, -1])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        accuracies.append(acc)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Increase (1)', 'Decrease (-1)'])\n",
    "        disp.plot(ax=axes[row, col_idx], cmap='Blues', colorbar=False)\n",
    "        axes[row, col_idx].set_title(f'{label}\\nAccuracy: {acc:.2%}')\n",
    "    else:\n",
    "        axes[row, col_idx].set_visible(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Print accuracy for each horizon\n",
    "for i, acc in enumerate(accuracies, 1):\n",
    "    print(f'Accuracy for {i} min: {acc:.2%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
