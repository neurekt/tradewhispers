{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c897916",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7817e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a9434b",
   "metadata": {},
   "source": [
    "### Initial preprocessing: raw -> interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda18fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(input, output):\n",
    "    usecols = ['date', 'time', 'HEADING']\n",
    "    df = pd.read_excel(input, usecols=usecols, engine=\"openpyxl\")\n",
    "\n",
    "    d = df['date'].astype(str).str.strip()\n",
    "    t = df['time'].astype(str).str.strip()\n",
    "\n",
    "    # Always discard any time from 'date' and append the separate 'time'\n",
    "    d_no_time = d.str.replace(r'([ T]\\d{1,2}:\\d{2}(:\\d{2})?)$', '', regex=True)\n",
    "    combined = d_no_time + \" \" + t\n",
    "\n",
    "    # Parse with dayfirst assumption, retry with monthfirst if needed\n",
    "    parsed = pd.to_datetime(combined, errors='coerce', dayfirst=True)\n",
    "    mask = parsed.isna()\n",
    "    if mask.any():\n",
    "        parsed.loc[mask] = pd.to_datetime(combined[mask], errors='coerce', dayfirst=False)\n",
    "\n",
    "    # Normalize to one consistent format\n",
    "    df['date'] = parsed.dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    df = df[['date', 'HEADING']].rename(columns={'HEADING': 'headline'})\n",
    "    df = df.dropna(subset=['date'])\n",
    "    df['headline'] = df['headline'].astype(str).str.replace(r'[\\r\\n]+', ' ', regex=True)\n",
    "\n",
    "    Path(output).parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(output, index=False, encoding='utf-8')\n",
    "\n",
    "load_corpus(\"../data/raw/corpus.xlsx\", \"../data/interim/corpus.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e8c13",
   "metadata": {},
   "source": [
    "### Final preprocessing: interim -> processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8705d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of data before August 1 (that's when we stop trading)\n",
    "df = pd.read_csv(\"../data/interim/corpus.csv\", parse_dates=[\"date\"])\n",
    "df['date'] = pd.to_datetime(df['date'], errors=\"coerce\")\n",
    "df = df.rename(columns={\"date\": \"timestamp\"})\n",
    "cutoff = pd.to_datetime(\"2025-07-31\")\n",
    "df = df[df[\"timestamp\"] <= cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "988a8fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates:\n",
      "                timestamp                                           headline\n",
      "239   2024-11-26 10:02:00                                  Reação ao IPCA-15\n",
      "242   2024-11-26 10:02:00                                  Reação ao IPCA-15\n",
      "488   2024-11-28 09:02:00  AOVIVO/Haddad sobre IR: Nosso objetivo é que e...\n",
      "489   2024-11-28 09:02:00  Ela irá beneficiar todo mundo que ganha até 5 ...\n",
      "490   2024-11-28 09:02:00  Com essa fórmula de cálculo, a suposta renúnci...\n",
      "493   2024-11-28 09:02:00  AOVIVO/Haddad sobre IR: Nosso objetivo é que e...\n",
      "494   2024-11-28 09:02:00  Ela irá beneficiar todo mundo que ganha até 5 ...\n",
      "495   2024-11-28 09:02:00  Com essa fórmula de cálculo, a suposta renúnci...\n",
      "599   2024-11-28 11:54:00  MERCADOS:  Sob pressão do fiscal, Ibovespa ame...\n",
      "600   2024-11-28 11:54:00  MERCADOS:  Sob pressão do fiscal, Ibovespa ame...\n",
      "856   2024-12-02 10:56:00  AOVIVO/Galípolo diz que a questão da meta é pá...\n",
      "857   2024-12-02 10:56:00  AOVIVO/Galípolo diz que a questão da meta é pá...\n",
      "1445  2024-12-06 09:22:00  MERCADOS: dolar e juros sobem com fiscal no ra...\n",
      "1446  2024-12-06 09:22:00  MERCADOS: dolar e juros sobem com fiscal no ra...\n",
      "1521  2024-12-06 12:54:00  Fed/Goolsbee: Inflação cai, mas se estabilizar...\n",
      "1522  2024-12-06 12:54:00  Fed/Goolsbee: Inflação cai, mas se estabilizar...\n",
      "4298  2025-01-10 12:14:00                                                NaN\n",
      "4301  2025-01-10 12:14:00                                                NaN\n",
      "5340  2025-01-24 12:52:00                                                NaN\n",
      "5341  2025-01-24 12:52:00                                                NaN\n",
      "5703  2025-01-30 10:31:00  Lula comeca daqui a pouco entrevista coletiva ...\n",
      "5704  2025-01-30 10:31:00  Lula comeca daqui a pouco entrevista coletiva ...\n",
      "6454  2025-02-10 10:07:00  Haddad deve discutir projeto pe-de-meia com mi...\n",
      "6455  2025-02-10 10:07:00  Haddad deve discutir projeto pe-de-meia com mi...\n",
      "6647  2025-02-12 10:02:00  Comeca evento com presenca de Gabriel Galipolo...\n",
      "6648  2025-02-12 10:02:00  Comeca evento com presenca de Gabriel Galipolo...\n",
      "7114  2025-02-18 12:49:00  Fed/Daly:  Presidente do Fed de sao Francisco ...\n",
      "7115  2025-02-18 12:49:00  Fed/Daly:  Presidente do Fed de sao Francisco ...\n",
      "7401  2025-02-21 11:29:00  AOVIVO/Nilton David: A demanda extraordinaria ...\n",
      "7402  2025-02-21 11:29:00  AOVIVO/Nilton David: A demanda extraordinaria ...\n",
      "11506 2025-05-07 12:21:00  EUA/Bessent: Reuniao com autoridades chinesas ...\n",
      "11507 2025-05-07 12:21:00  EUA/Bessent: Reuniao com autoridades chinesas ...\n",
      "11702 2025-05-09 10:04:00  EMPRESAS: Gol convoca assembleia para 30 de ma...\n",
      "11703 2025-05-09 10:04:00  EMPRESAS: Gol convoca assembleia para 30 de ma...\n",
      "11891 2025-05-13 10:39:00  Citi reitera recomendacao de compra para Sabes...\n",
      "11892 2025-05-13 10:39:00  Citi reitera recomendacao de compra para Sabes...\n",
      "12081 2025-05-15 13:32:00  Sem presenca de Putin, Zelensky cancela ida a ...\n",
      "12082 2025-05-15 13:32:00  Sem presenca de Putin, Zelensky cancela ida a ...\n",
      "12219 2025-05-19 10:48:00  Galipolo/Goldman:  Vai ser um longo periodo e ...\n",
      "12220 2025-05-19 10:48:00  Galipolo/Goldman:  Vai ser um longo periodo e ...\n",
      "12442 2025-05-22 09:02:00  DOLAR sobe a R$ 5,6529 (+0,19%) e DOLAR futuro...\n",
      "12443 2025-05-22 09:02:00  DOLAR sobe a R$ 5,6529 (+0,19%) e DOLAR futuro...\n",
      "12458 2025-05-22 10:52:00  China fecha acordo de livre comercio atualizad...\n",
      "12459 2025-05-22 10:52:00  China fecha acordo de livre comercio atualizad...\n"
     ]
    }
   ],
   "source": [
    "# get rid of duplicates\n",
    "dup = df[df.duplicated(subset=[\"timestamp\", \"headline\"], keep=False)]\n",
    "print(\"Duplicates:\")\n",
    "print(dup)\n",
    "df = df.drop_duplicates(subset=[\"timestamp\", \"headline\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e911ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOJIBAKE_MAP = {\n",
    "    \"√°\": \"á\", \"√£\": \"ã\", \"√©\": \"é\", \"√º\": \"ú\", \"√≥\": \"ó\", \"√±\": \"ñ\",\n",
    "    \"√§\": \"ç\", \"√¶\": \"õ\", \"√•\": \"í\", \"√∫\": \"ú\", \"√™\": \"’\",\n",
    "    \"ß\": \"ç\", \"‚Äò\": \"’\", \"‚Äú\": \"“\", \"‚Äù\": \"”\", \"‚Äì\": \"–\",\n",
    "    \"´\": \"’\",\n",
    "}\n",
    "\n",
    "def clean_headline(text: str, min_chars: int = 40) -> str | None:\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "\n",
    "    # fix mojibake\n",
    "    for bad, good in MOJIBAKE_MAP.items():\n",
    "        text = text.replace(bad, good)\n",
    "\n",
    "    # strip newswire prefixes and junk symbols\n",
    "    text = re.sub(r\"^(\\*|BC:|[A-Za-zÀ-ÿ]+/|[A-Za-zÀ-ÿ]+:)\\s*\", \"\", text)\n",
    "\n",
    "    # normalize characters/spaces, strip trailing colon\n",
    "    text = re.sub(r\"[^\\w\\s.,;:!?-ÁÉÍÓÚÂÊÔÃÕáéíóúâêôãõçÇñÑ]+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(r\":$\", \"\", text).strip()\n",
    "\n",
    "    # drop if too short in characters\n",
    "    return text if len(text) >= min_chars else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81cb76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning but keep both original and cleaned values\n",
    "df[\"cleaned_headline\"] = df[\"headline\"].apply(clean_headline)\n",
    "\n",
    "# Separate valid and removed rows\n",
    "removed_df = df[df[\"cleaned_headline\"].isna()].copy().drop(columns=[\"cleaned_headline\"])\n",
    "cleaned_df = df[df[\"cleaned_headline\"].notna()].copy()\n",
    "\n",
    "# Replace headline with cleaned version for the kept rows\n",
    "cleaned_df = cleaned_df.drop(columns=[\"headline\"])\n",
    "cleaned_df = cleaned_df.rename(columns={\"cleaned_headline\": \"headline\"})\n",
    "\n",
    "# Save outputs\n",
    "cleaned_df.to_csv(\"../data/processed/corpus.csv\", index=False, encoding=\"utf-8\")\n",
    "removed_df.to_csv(\"../data/interim/corpus-removed.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
