{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd9e6f2",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d32c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ad4d94",
   "metadata": {},
   "source": [
    "Bom Dia Mercado (BDM) → xlsx file with BDM articles and more → preprocessing to CSV → export to repository → final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f47c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 invalid rows found.\n",
      "Empty DataFrame\n",
      "Columns: [Timestamp, HEADING, ARTICLE CONTENT, COMMENTS]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Load the dataset\n",
    "df = pd.read_excel(\"../data/raw/bdm-corpus-2.xlsx\")\n",
    "\n",
    "# Step 1–3: Normalize individual DATE and TIME cells\n",
    "def parse_datetime_components(date_cell, time_cell):\n",
    "    try:\n",
    "        # Coerce both to string and strip spaces\n",
    "        date_str = str(date_cell).strip()\n",
    "        time_str = str(time_cell).strip()\n",
    "        \n",
    "        # Combine and parse flexibly\n",
    "        dt = parser.parse(f\"{date_str} {time_str}\", dayfirst=True)\n",
    "        return dt.isoformat()\n",
    "    except Exception:\n",
    "        return pd.NaT  # mark invalid rows\n",
    "\n",
    "# Step 4: Create ISO 8601 Timestamp column\n",
    "df['Timestamp'] = df.apply(lambda row: parse_datetime_components(row['DATE'], row['TIME']), axis=1)\n",
    "\n",
    "# Step 5: Drop old columns\n",
    "df.drop(columns=['DATE', 'TIME', 'Index', 'DIRECTION', 'BRER', 'LABEL'], inplace=True)\n",
    "\n",
    "# Step 6: Clean newlines in ARTICLE CONTENT and COMMENTS\n",
    "for col in ['HEADING', 'ARTICLE CONTENT', 'COMMENTS']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.replace(r'[\\r\\n]+', ' ', regex=True).str.strip()\n",
    "\n",
    "# Step 7: Reorder columns\n",
    "df = df[['Timestamp'] + [col for col in df.columns if col != 'Timestamp']]\n",
    "\n",
    "# Step 8: Save as CSV\n",
    "df.to_csv(\"../data/interim/bdm-corpus-2.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Step 9: Check for invalid rows (passed)\n",
    "invalid_rows = df[df['Timestamp'].isna()]\n",
    "print(f\"{len(invalid_rows)} invalid rows found.\")\n",
    "print(invalid_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c9b77",
   "metadata": {},
   "source": [
    "Bloomberg → Download USD/BRL exchange rates as excel file → preprocess to CSV → export to repository → final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2ae1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 invalid rows found.\n",
      "Empty DataFrame\n",
      "Columns: [Timestamp, USD/BRL]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Load the dataset\n",
    "df = pd.read_excel(\"../data/raw/usd-brl.xlsx\")\n",
    "\n",
    "# Step 1: Clean column names\n",
    "df.columns = [col.strip() for col in df.columns]\n",
    "df.rename(columns={\"Date\": \"Raw Timestamp\", \"Último preço\": \"USD/BRL\"}, inplace=True)\n",
    "\n",
    "# Step 2: Parse \"Raw Timestamp\" into ISO 8601 format\n",
    "def parse_iso8601(raw):\n",
    "    try:\n",
    "        return parser.parse(str(raw).strip()).isoformat()\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "df[\"Timestamp\"] = df[\"Raw Timestamp\"].apply(parse_iso8601)\n",
    "\n",
    "# Step 3: Drop the original column\n",
    "df.drop(columns=[\"Raw Timestamp\"], inplace=True)\n",
    "\n",
    "# Step 4: Reorder columns\n",
    "df = df[[\"Timestamp\", \"USD/BRL\"]]\n",
    "\n",
    "# Step 5: Save to CSV\n",
    "df.to_csv(\"../data/processed/usd-brl.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# Step 6: Print invalid rows (if any)\n",
    "invalid_rows = df[df[\"Timestamp\"].isna()]\n",
    "print(f\"{len(invalid_rows)} invalid rows found.\")\n",
    "print(invalid_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c9aed9",
   "metadata": {},
   "source": [
    "data/interim/bdm-corpus-2.csv + data/processed/usd-brl.csv -> merge -> data/processed/bdm-corpus-2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3083ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "THE ABOVE VERSIONS WENT INTO INTERIM\n",
    "\n",
    "Below we will process a universal dataset that contains both the Allen corpus and the USD/BRL exchange rate.\n",
    "This dataset can be used for any experiment, including the FINBERT baseline model.\n",
    "\n",
    "Step 1: Load interim data\n",
    "Step 2: Match exchange rates to each row in the Allen corpus by matching timestamps\n",
    "Step 3: Save the combined dataset as a new CSV file into data/processed as the universal dataset\n",
    "Step 4: Refactor the code to a reusable script that can be run from the command line\n",
    "'''\n",
    "\n",
    "# Step 1: Load interim data\n",
    "bdm_df = pd.read_csv(\"../data/interim/bdm-corpus-2.csv\", parse_dates=['Timestamp'])\n",
    "usd_brl_df = pd.read_csv(\"../data/processed/usd-brl.csv\", parse_dates=['Timestamp'])\n",
    "\n",
    "# Step 2: Merge datasets on Timestamp\n",
    "merged_df = pd.merge(bdm_df, usd_brl_df, on='Timestamp', how='left', suffixes=('', '_USD_BRL'))\n",
    "\n",
    "# Step 3: Save the combined dataset\n",
    "merged_df.to_csv(\"../data/processed/bdm-corpus-2.csv\", index=False, encoding='utf-8-sig')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
