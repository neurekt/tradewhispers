{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0599d14",
   "metadata": {},
   "source": [
    "# Baseline Experiment - Sentiment Analysis\n",
    "## Model: FinBERT PT-BR\n",
    "- Current Issue: How to compute exchange rate forward returns if news is released on weekends and usd/brl isn't being traded? There's no matching exchange rate unless we use Friday's closing and Monday's opening to measure the change.\n",
    "- Hypothesis (h1a): Sentiment outputs, mapped to direction, can predict short-term exchange rate movements.\n",
    "- Objective: A baseline comparison before testing hyped-up LLMs capabilities\n",
    "- Value Proposition: This is the first known study to be conducted on applying language models to trade in emerging currency markets. Especially in a multilingual context.\n",
    "- Why sentiment analysis as baseline: \n",
    "    - FinBERT is widely cited in financial NLP literature\n",
    "    - outperforms general BERT and lexicon-based models on tasks like financial sentiment classification\n",
    "    - Traditional ML methods rely on sparse inputs or static word embeddings (like Word2Vec) which don't capture context\n",
    "    - sentiment analysis is commonly used in generating trading signals, however I believe that market does not operate\n",
    "    on whether a piece of text is happy or sad. Thus, I'm expecting the following experiments to outperform this baseline. \n",
    "    I just want to rule sentiment analysis out of the picture. \"Predicting directional movement\" is a better approach.\n",
    "    - it was used as a benchmark in very similar paper found at https://doi.org/10.1016/j.mlwa.2023.100508\n",
    "\n",
    "- Independent Variable (Predictor):\n",
    "    - Text: headline / article content\n",
    "    - Category: FinBERT sentiment output\n",
    "    - Binary Label: heuristic mapping (positive -> 1, negative -> -1) (bullish or bearish in commercial terms)\n",
    "    - (POSSIBLY CONSIDER as a control var/experiment?): Multi-class Label: neutral (0) label defined by threshold label (min exchange rate % change)\n",
    "\n",
    "- Dependent Variable (Ground Truth):\n",
    "    - Directional Movement: binary direction of exchange rate following news timestamp (time frame TBD)\n",
    "    - (POSSIBLY CONSIDER?): percent change in exchange rate over defined window? Measures profitability...\n",
    "\n",
    "- Dataset Creation Process:\n",
    "    - News Data: There are only 3,519 headlines before **Timestamp[2024-12-30 17:38:00]**, which is the latest possible timestamp for a t+20 analysis (since exchange rate data ends at 17:58:00). In total, the dataset contains 4630 headlines. These cannot be used until exchange rates are available on a minute-level basis for December 30, 2024, to January 15, 2025. \n",
    "        - Dataset Creation Process: Bom Dia Mercado (BDM) → Eli formatted news data into excel file → preprocess.ipynb → export to repo → final dataset\n",
    "    - FX Rate Data: Minute-level time series of USD/BRL exchange rates, synchronized with news timestamps in pandas ISO datetime object format.\n",
    "        - Dataset Creation Process: Bloomberg → retrieve USD/BRL exchange rates as excel file → preprocess.ipynb → export to repo → final dataset\n",
    "\n",
    "- Model:\n",
    "    - HuggingFace Transformers Model: lucas-leme/FinBERT-PT-BR\n",
    "\n",
    "- RESULTS:\n",
    "    - did on colab T4 GPU through batches & did on local CPU. Same exact results. Saved exact model configurations into checkpoints/exp001\n",
    "    - t+7 horizon: best accuracy - 48.3% OVERALL accuracy through binary classification by fine-tuned financial pt-br sentiment analysis\n",
    "\n",
    "Notes:\n",
    "    - Dataset used in this experiment: experimental_dataset.csv with 3519 news headlines \n",
    "    - USING HEADLINES ONLY not ARTICLE CONTENT and COMMENTS as past research has shown that these are not useful for prediction purposes, and they are noisy.\n",
    "    - straightforward t+1 to t+20 prediction horizon by computing directional movement using following exchange rate minus exchange rate at t for each increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69ca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Doc 1 Methodology: Load lucas-leme/FinBERT-PT-BR / tokenizer → tokenize headlines → FinBERT → sentiment output\n",
    "\n",
    "HuggingFace notes\n",
    "- BERT is an architecture while lucas-leme/FinBERT-PT-BR is a checkpoint\n",
    "- import the model specific class from the transformers library\n",
    "- call from_pretrained() from the above class to download the model's weights (pytorch_model.bin) and configuration settings (config.json)\n",
    "- tokenizer is a class from the transformers library that finds the tokenizer specified in the checkpoint and fully preprocesses input text\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ce3698",
   "metadata": {},
   "source": [
    "## Load Model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7efff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Load from HuggingFace\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lucas-leme/FinBERT-PT-BR\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"lucas-leme/FinBERT-PT-BR\")\n",
    "\n",
    "# Save locally\n",
    "model.save_pretrained(\"../checkpoints/exp001\")\n",
    "tokenizer.save_pretrained(\"../checkpoints/exp001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d427ac4",
   "metadata": {},
   "source": [
    "## Load Model from Local Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba33bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertForSequenceClassification, pipeline\n",
    "import pandas as pd\n",
    "\n",
    "local_path = \"../../checkpoints/exp001\"\n",
    "\n",
    "df = pd.read_csv(\"../../data/processed/experimental_dataset.csv\")  # Now we can use paths relative to project root\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(local_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0289cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    local_path,\n",
    "    trust_remote_code=True,\n",
    "    local_files_only=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    local_path,\n",
    "    trust_remote_code=True,\n",
    "    local_files_only=True\n",
    ")\n",
    "finbert_pipeline = pipeline(\n",
    "    task='text-classification',\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "# mapping predictions\n",
    "pred_mapper = {\n",
    "    0: \"POSITIVE\",\n",
    "    1: \"NEGATIVE\", \n",
    "    2: \"NEUTRAL\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a687e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "results = []\n",
    "for headline in df['Headline']:\n",
    "    result = finbert_pipeline(headline)[0]\n",
    "\n",
    "    if result['label'] == pred_mapper[0]:  # POSITIVE\n",
    "        sentiment = 1\n",
    "    elif result['label'] == pred_mapper[1]:  # NEGATIVE\n",
    "        sentiment = -1\n",
    "    elif result['label'] == pred_mapper[2]:  # NEUTRAL\n",
    "        sentiment = 0\n",
    "    results.append(sentiment)\n",
    "\n",
    "# save predictions to the dataframe\n",
    "df['Prediction'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../results/exp001/exp001.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0632e388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "-1    1542\n",
      " 0    1069\n",
      " 1     908\n",
      "Name: count, dtype: int64 \n",
      "total vals (it checks out - good): 3519\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../../results/exp001/exp001_colab.csv\")\n",
    "preds = df['Prediction']\n",
    "print(preds.value_counts(), '\\n' 'total vals (it checks out - good): 'f'{preds.value_counts().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a6bc562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files equal\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_csvs(file1, file2):\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "\n",
    "    # sort columns and rows for a strict, order-insensitive comparison\n",
    "    df1_sorted = df1.sort_index(axis=1).sort_values(by=df1.columns.tolist()).reset_index(drop=True)\n",
    "    df2_sorted = df2.sort_index(axis=1).sort_values(by=df2.columns.tolist()).reset_index(drop=True)\n",
    "\n",
    "    return df1_sorted.equals(df2_sorted)\n",
    "\n",
    "are_equal = compare_csvs(\"../../results/exp001/exp001_colab.csv\", \"../../results/exp001/exp001.csv\")\n",
    "print(\"files equal\" if are_equal else \"files differ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5f66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for Forward Return t+1:\n",
      "[[449 259]\n",
      " [543 256]]\n",
      "\n",
      "Confusion matrix for Forward Return t+2:\n",
      "[[620 401]\n",
      " [703 411]]\n",
      "\n",
      "Confusion matrix for Forward Return t+3:\n",
      "[[661 436]\n",
      " [797 439]]\n",
      "\n",
      "Confusion matrix for Forward Return t+4:\n",
      "[[684 426]\n",
      " [826 463]]\n",
      "\n",
      "Confusion matrix for Forward Return t+5:\n",
      "[[695 438]\n",
      " [832 461]]\n",
      "\n",
      "Confusion matrix for Forward Return t+6:\n",
      "[[684 440]\n",
      " [841 462]]\n",
      "\n",
      "Confusion matrix for Forward Return t+7:\n",
      "[[698 421]\n",
      " [831 476]]\n",
      "\n",
      "Confusion matrix for Forward Return t+8:\n",
      "[[686 428]\n",
      " [840 473]]\n",
      "\n",
      "Confusion matrix for Forward Return t+9:\n",
      "[[661 428]\n",
      " [865 473]]\n",
      "\n",
      "Confusion matrix for Forward Return t+10:\n",
      "[[655 421]\n",
      " [878 480]]\n",
      "\n",
      "Confusion matrix for Forward Return t+11:\n",
      "[[645 424]\n",
      " [886 477]]\n",
      "\n",
      "Confusion matrix for Forward Return t+12:\n",
      "[[652 428]\n",
      " [880 473]]\n",
      "\n",
      "Confusion matrix for Forward Return t+13:\n",
      "[[648 415]\n",
      " [883 485]]\n",
      "\n",
      "Confusion matrix for Forward Return t+14:\n",
      "[[635 414]\n",
      " [892 486]]\n",
      "\n",
      "Confusion matrix for Forward Return t+15:\n",
      "[[643 403]\n",
      " [889 499]]\n",
      "\n",
      "Confusion matrix for Forward Return t+16:\n",
      "[[633 400]\n",
      " [896 500]]\n",
      "\n",
      "Confusion matrix for Forward Return t+17:\n",
      "[[643 400]\n",
      " [884 501]]\n",
      "\n",
      "Confusion matrix for Forward Return t+18:\n",
      "[[648 408]\n",
      " [882 494]]\n",
      "\n",
      "Confusion matrix for Forward Return t+19:\n",
      "[[658 409]\n",
      " [875 492]]\n",
      "\n",
      "Confusion matrix for Forward Return t+20:\n",
      "[[658 416]\n",
      " [874 486]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "filtered_df = df[df[\"Prediction\"] != 0].copy() # no DA for neutral (0), just binary classification. Rid of all neutral predictions \n",
    "\n",
    "forward_return_cols = [col for col in df.columns if col.startswith(\"Forward Return t+\")]\n",
    "\n",
    "conf_matrices = {}\n",
    "'''\n",
    "[[TN, FP],\n",
    " [FN, TP]]\n",
    "'''\n",
    "\n",
    "for col in forward_return_cols:\n",
    "    y_true = filtered_df[col]\n",
    "    y_pred = filtered_df[\"Prediction\"]\n",
    "\n",
    "    #  -1 and 1 (exclude 0s in ground truth if present)\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "\n",
    "    #  confusion matrix with labels fixed to [-1, 1]\n",
    "    cm = confusion_matrix(y_true_filtered, y_pred_filtered, labels=[-1, 1])\n",
    "    conf_matrices[col] = cm\n",
    "\n",
    "# Display one example\n",
    "for k, v in conf_matrices.items():\n",
    "    print(f\"Confusion matrix for {k}:\\n{v}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20ce7e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Horizon</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forward Return t+1</td>\n",
       "      <td>0.467817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forward Return t+2</td>\n",
       "      <td>0.482904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forward Return t+3</td>\n",
       "      <td>0.471496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Forward Return t+4</td>\n",
       "      <td>0.478116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forward Return t+5</td>\n",
       "      <td>0.476505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Forward Return t+6</td>\n",
       "      <td>0.472188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Forward Return t+7</td>\n",
       "      <td>0.483924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Forward Return t+8</td>\n",
       "      <td>0.477544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Forward Return t+9</td>\n",
       "      <td>0.467244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Forward Return t+10</td>\n",
       "      <td>0.466311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Forward Return t+11</td>\n",
       "      <td>0.461349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Forward Return t+12</td>\n",
       "      <td>0.462392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Forward Return t+13</td>\n",
       "      <td>0.466063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Forward Return t+14</td>\n",
       "      <td>0.461887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Forward Return t+15</td>\n",
       "      <td>0.469187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Forward Return t+16</td>\n",
       "      <td>0.466447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Forward Return t+17</td>\n",
       "      <td>0.471170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Forward Return t+18</td>\n",
       "      <td>0.469572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Forward Return t+19</td>\n",
       "      <td>0.472473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Forward Return t+20</td>\n",
       "      <td>0.470008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Horizon  Accuracy\n",
       "0    Forward Return t+1  0.467817\n",
       "1    Forward Return t+2  0.482904\n",
       "2    Forward Return t+3  0.471496\n",
       "3    Forward Return t+4  0.478116\n",
       "4    Forward Return t+5  0.476505\n",
       "5    Forward Return t+6  0.472188\n",
       "6    Forward Return t+7  0.483924\n",
       "7    Forward Return t+8  0.477544\n",
       "8    Forward Return t+9  0.467244\n",
       "9   Forward Return t+10  0.466311\n",
       "10  Forward Return t+11  0.461349\n",
       "11  Forward Return t+12  0.462392\n",
       "12  Forward Return t+13  0.466063\n",
       "13  Forward Return t+14  0.461887\n",
       "14  Forward Return t+15  0.469187\n",
       "15  Forward Return t+16  0.466447\n",
       "16  Forward Return t+17  0.471170\n",
       "17  Forward Return t+18  0.469572\n",
       "18  Forward Return t+19  0.472473\n",
       "19  Forward Return t+20  0.470008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#accuracies\n",
    "\n",
    "filtered_df = df[df[\"Prediction\"] != 0].copy()\n",
    "\n",
    "forward_return_cols = [col for col in df.columns if col.startswith(\"Forward Return t+\")]\n",
    "accuracies = {}\n",
    "\n",
    "for col in forward_return_cols:\n",
    "    y_true = filtered_df[col]\n",
    "    y_pred = filtered_df[\"Prediction\"]\n",
    "    mask = y_true != 0\n",
    "    accuracy = (y_true[mask] == y_pred[mask]).mean()\n",
    "    accuracies[col] = accuracy\n",
    "\n",
    "accuracy_df = pd.DataFrame.from_dict(accuracies, orient='index', columns=['Accuracy'])\n",
    "accuracy_df.index.name = 'Horizon'\n",
    "accuracy_df.reset_index(inplace=True)\n",
    "\n",
    "display(accuracy_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
