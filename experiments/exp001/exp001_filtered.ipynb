{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0599d14",
   "metadata": {},
   "source": [
    "# exp001 - Baseline Experiment\n",
    "- https://drive.google.com/file/d/1sV2DSHaIFE-BvPs0POqH3y4qMH883j6N/view?usp=drive_link\n",
    "- Hypothesis (h1a): Sentiment outputs, mapped to direction, can predict short-term exchange rate movements - won't perform well because the model lacks domain specific context\n",
    "- Objective: A baseline comparison before testing hyped-up LLMs capabilities\n",
    "- Value Proposition: This is the first known study to be conducted on applying language models to trade in emerging currency markets. Especially in a multilingual context.\n",
    "- Why sentiment analysis as baseline: \n",
    "    - FinBERT is widely cited in financial NLP literature\n",
    "    - Outperforms general BERT and lexicon-based models on tasks like financial sentiment classification\n",
    "    - Traditional ML methods rely on sparse inputs or static word embeddings (like Word2Vec) which don't capture context\n",
    "    - Sentiment analysis is commonly used in generating trading signals, however I believe that market does not operate\n",
    "    on whether a piece of text is happy or sad. Thus, I'm expecting the following experiments to outperform this baseline. \n",
    "    I just want to rule sentiment analysis out of the picture. \"Predicting directional movement\" is a better approach.\n",
    "    - It was used as a benchmark in very similar paper found at https://doi.org/10.1016/j.mlwa.2023.100508\n",
    "\n",
    "- Model:\n",
    "    - HuggingFace Transformers Model: lucas-leme/FinBERT-PT-BR\n",
    "\n",
    "- Independent Variable (Predictor):\n",
    "    - Text: headline\n",
    "    - Category: FinBERT sentiment output\n",
    "    - Binary Label: heuristic mapping (positive -> 1, negative -> -1) (bullish or bearish in commercial terms)\n",
    "\n",
    "- Dependent Variable (Ground Truth):\n",
    "    - Directional Movement: binary direction of exchange rate following news timestamp (exchange rate change after t + 5 minutes)\n",
    "\n",
    "- Dataset Creation Process:\n",
    "    - Stage 4 test dataset\n",
    "\n",
    "- Experimentation:\n",
    "    - Encoder-only (representation model) - BERT - FinBERT-PT-BR is a domain specific version of FinBERT, another domain specific BERT model\n",
    "    - Methodology: Load lucas-leme/FinBERT-PT-BR / tokenizer → tokenize headlines → FinBERT → sentiment output\n",
    "\n",
    "- RESULTS:\n",
    "    - Bad as expected, check below\n",
    "\n",
    "Notes:\n",
    "    - Using HEADLINES ONLY not ARTICLE CONTENT and COMMENTS as past research has shown that these are not useful for prediction purposes, and they are noisy. No timestamps either because that isn't sentiment.\n",
    "\n",
    "HuggingFace notes\n",
    "- BERT is an architecture while lucas-leme/FinBERT-PT-BR is a checkpoint\n",
    "- import the model specific class from the transformers library\n",
    "- local: call from_pretrained() from the above class to download model's weights (pytorch_model.bin) and config settings (config.json)\n",
    "- tokenizer is a class from the transformers library that finds the tokenizer specified in the checkpoint and fully preprocesses input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0632e388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "-1    310\n",
      " 1    190\n",
      "Name: count, dtype: int64 \n",
      "Total values: 500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../../results/exp001/results.csv\")\n",
    "preds = df['Prediction']\n",
    "print(preds.value_counts(), '\\n' 'Total values: 'f'{preds.value_counts().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeec4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {1: 'Decrease', -1: 'Increase', 0: 'Stable'}\n",
    "df['Prediction'] = df['Prediction'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4e5f66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Increase</th>\n",
       "      <th>Predicted Decrease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Increase</th>\n",
       "      <td>161</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Decrease</th>\n",
       "      <td>149</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Increase  Predicted Decrease\n",
       "Actual Increase                 161                 104\n",
       "Actual Decrease                 149                  86"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "labels = [\"Increase\", \"Decrease\"]\n",
    "\n",
    "cm = confusion_matrix(df[\"Direction\"], df[\"Prediction\"], labels=labels)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[f\"Actual {label}\" for label in labels],\n",
    "    columns=[f\"Predicted {label}\" for label in labels]\n",
    ")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "display(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ce7e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Increase      0.519     0.608     0.560       265\n",
      "    Decrease      0.453     0.366     0.405       235\n",
      "\n",
      "    accuracy                          0.494       500\n",
      "   macro avg      0.486     0.487     0.482       500\n",
      "weighted avg      0.488     0.494     0.487       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Normalize predictions (just in case)\n",
    "df[\"Prediction\"] = df[\"Prediction\"].str.strip().str.capitalize()\n",
    "df[\"Direction\"] = df[\"Direction\"].str.strip().str.capitalize()\n",
    "\n",
    "# Report\n",
    "report = classification_report(\n",
    "    df[\"Direction\"], df[\"Prediction\"],\n",
    "    labels=[\"Increase\", \"Decrease\"],\n",
    "    target_names=[\"Increase\", \"Decrease\"],\n",
    "    digits=3\n",
    ")\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
