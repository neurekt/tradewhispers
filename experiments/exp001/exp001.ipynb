{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0599d14",
   "metadata": {},
   "source": [
    "# Baseline Experiment\n",
    "- Hypothesis (h1a): Sentiment outputs, mapped to direction, can predict short-term exchange rate movements.\n",
    "- Objective: A baseline comparison before testing hyped-up LLMs capabilities\n",
    "- Value Proposition: This is the first known study to be conducted on applying language models to trade in emerging currency markets. Especially in a multilingual context.\n",
    "- Why sentiment analysis as baseline: \n",
    "    - FinBERT is widely cited in financial NLP literature\n",
    "    - Outperforms general BERT and lexicon-based models on tasks like financial sentiment classification\n",
    "    - Traditional ML methods rely on sparse inputs or static word embeddings (like Word2Vec) which don't capture context\n",
    "    - Sentiment analysis is commonly used in generating trading signals, however I believe that market does not operate\n",
    "    on whether a piece of text is happy or sad. Thus, I'm expecting the following experiments to outperform this baseline. \n",
    "    I just want to rule sentiment analysis out of the picture. \"Predicting directional movement\" is a better approach.\n",
    "    - It was used as a benchmark in very similar paper found at https://doi.org/10.1016/j.mlwa.2023.100508\n",
    "\n",
    "- Independent Variable (Predictor):\n",
    "    - Text: headline / article content\n",
    "    - Category: FinBERT sentiment output\n",
    "    - Binary Label: heuristic mapping (positive -> 1, negative -> -1) (bullish or bearish in commercial terms)\n",
    "    - (POSSIBLY CONSIDER as a control var/experiment?): Multi-class Label: neutral (0) label defined by threshold label (min exchange rate % change)\n",
    "\n",
    "- Dependent Variable (Ground Truth):\n",
    "    - Directional Movement: binary direction of exchange rate following news timestamp (time frame TBD)\n",
    "    - (POSSIBLY CONSIDER?): percent change in exchange rate over defined window? Measures profitability...\n",
    "\n",
    "- Dataset Creation Process:\n",
    "    - News Data: There are only 3,519 headlines before **Timestamp[2024-12-30 17:38:00]**, which is the latest possible timestamp for a t+20 analysis (since exchange rate data ends at 17:58:00). In total, the dataset contains 4630 headlines. These cannot be used until exchange rates are available on a minute-level basis for December 30, 2024, to January 15, 2025. \n",
    "        - Dataset Creation Process: Bom Dia Mercado (BDM) → Eli formatted news data into excel file → preprocess.ipynb → export to repo → final dataset\n",
    "    - FX Rate Data: Minute-level time series of USD/BRL exchange rates, synchronized with news timestamps in pandas ISO datetime object format.\n",
    "        - Dataset Creation Process: Bloomberg → retrieve USD/BRL exchange rates as excel file → preprocess.ipynb → export to repo → final dataset\n",
    "    - Final Dataset: experimental_dataset.csv\n",
    "        - Took the last available exchange rate for any news released outside of market hours. Process described in preprocess.ipynb. \n",
    "\n",
    "- Methodology: Sentiment Analysis\n",
    "    - Encoder-only (representation model) - BERT - FinBERT-PT-BR is a domain specific version of FinBERT, another domain specific BERT model\n",
    "- Model:\n",
    "    - HuggingFace Transformers Model: lucas-leme/FinBERT-PT-BR\n",
    "\n",
    "- RESULTS:\n",
    "\n",
    "Notes:\n",
    "    - Dataset used in this experiment: experimental_dataset.csv with 3519 news headlines \n",
    "    - Using HEADLINES ONLY not ARTICLE CONTENT and COMMENTS as past research has shown that these are not useful for prediction purposes, and they are noisy.\n",
    "    - Straightforward t+1 to t+20 prediction horizon by computing directional movement using following exchange rate minus exchange rate at t for each increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69ca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Doc 1 Methodology: Load lucas-leme/FinBERT-PT-BR / tokenizer → tokenize headlines → FinBERT → sentiment output\n",
    "\n",
    "HuggingFace notes\n",
    "- BERT is an architecture while lucas-leme/FinBERT-PT-BR is a checkpoint\n",
    "- import the model specific class from the transformers library\n",
    "- call from_pretrained() from the above class to download the model's weights (pytorch_model.bin) and configuration settings (config.json)\n",
    "- tokenizer is a class from the transformers library that finds the tokenizer specified in the checkpoint and fully preprocesses input text\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ce3698",
   "metadata": {},
   "source": [
    "## Load Model from HuggingFace (only need to do once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7efff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Load from HuggingFace\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lucas-leme/FinBERT-PT-BR\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"lucas-leme/FinBERT-PT-BR\")\n",
    "\n",
    "# Save locally\n",
    "model.save_pretrained(\"../checkpoints/exp001\")\n",
    "tokenizer.save_pretrained(\"../checkpoints/exp001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d427ac4",
   "metadata": {},
   "source": [
    "## Load Model from Local Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba33bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertForSequenceClassification, pipeline\n",
    "import pandas as pd\n",
    "\n",
    "local_path = \"../../checkpoints/exp001\"\n",
    "\n",
    "df = pd.read_csv(\"\") \n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(local_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0289cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    local_path,\n",
    "    trust_remote_code=True,\n",
    "    local_files_only=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    local_path,\n",
    "    trust_remote_code=True,\n",
    "    local_files_only=True\n",
    ")\n",
    "finbert_pipeline = pipeline(\n",
    "    task='text-classification',\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "# mapping predictions\n",
    "pred_mapper = {\n",
    "    0: \"POSITIVE\",\n",
    "    1: \"NEGATIVE\", \n",
    "    2: \"NEUTRAL\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a687e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "results = []\n",
    "for headline in df['Headline']:\n",
    "    result = finbert_pipeline(headline)[0]\n",
    "\n",
    "    if result['label'] == pred_mapper[0]:  # POSITIVE\n",
    "        sentiment = 1\n",
    "    elif result['label'] == pred_mapper[1]:  # NEGATIVE\n",
    "        sentiment = -1\n",
    "    elif result['label'] == pred_mapper[2]:  # NEUTRAL\n",
    "        sentiment = 0\n",
    "    results.append(sentiment)\n",
    "\n",
    "# save predictions to the dataframe\n",
    "df['Prediction'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../results/exp001/exp001.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd978db",
   "metadata": {},
   "source": [
    "## Analyze Colab Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0632e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../../results/exp001/exp001.csv\")\n",
    "preds = df['Prediction']\n",
    "print(preds.value_counts(), '\\n' 'total vals (it checks out - good): 'f'{preds.value_counts().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "filtered_df = df[df[\"Prediction\"] != 0].copy() # no DA for neutral (0), just binary classification. Rid of all neutral predictions \n",
    "\n",
    "forward_return_cols = [col for col in df.columns if col.startswith(\"Forward Return t+\")]\n",
    "\n",
    "conf_matrices = {}\n",
    "'''\n",
    "[[TN, FP],\n",
    " [FN, TP]]\n",
    "'''\n",
    "\n",
    "for col in forward_return_cols:\n",
    "    y_true = filtered_df[col]\n",
    "    y_pred = filtered_df[\"Prediction\"]\n",
    "\n",
    "    #  -1 and 1 (exclude 0s in ground truth if present)\n",
    "    mask = y_true != 0\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "\n",
    "    #  confusion matrix with labels fixed to [-1, 1]\n",
    "    cm = confusion_matrix(y_true_filtered, y_pred_filtered, labels=[-1, 1])\n",
    "    conf_matrices[col] = cm\n",
    "\n",
    "# Display one example\n",
    "for k, v in conf_matrices.items():\n",
    "    print(f\"Confusion matrix for {k}:\\n{v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ce7e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracies\n",
    "\n",
    "filtered_df = df[df[\"Prediction\"] != 0].copy()\n",
    "\n",
    "forward_return_cols = [col for col in df.columns if col.startswith(\"Forward Return t+\")]\n",
    "accuracies = {}\n",
    "\n",
    "for col in forward_return_cols:\n",
    "    y_true = filtered_df[col]\n",
    "    y_pred = filtered_df[\"Prediction\"]\n",
    "    mask = y_true != 0\n",
    "    accuracy = (y_true[mask] == y_pred[mask]).mean()\n",
    "    accuracies[col] = accuracy\n",
    "\n",
    "accuracy_df = pd.DataFrame.from_dict(accuracies, orient='index', columns=['Accuracy'])\n",
    "accuracy_df.index.name = 'Horizon'\n",
    "accuracy_df.reset_index(inplace=True)\n",
    "\n",
    "display(accuracy_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
