{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading Signal Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Core Libraries --------------------\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# -------------------- Text Processing --------------------\n",
    "import spacy\n",
    "from preprocessing import preprocess_text\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    ")\n",
    "\n",
    "# -------------------- Machine Learning --------------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "# -------------------- Visualization --------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm  # Jupyter-native progress bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory to the root of the project (go up one directory from notebooks to root)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "os.chdir(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "january = \"data/processed/bdm/2024-01.csv\"\n",
    "with open(january, \"r\", encoding=\"utf-8\") as file:\n",
    "    df_jan = pd.read_csv(file)\n",
    "\n",
    "february = \"data/processed/bdm/2024-02.csv\"\n",
    "with open(february, \"r\", encoding=\"utf-8\") as file:\n",
    "    df_feb = pd.read_csv(file)\n",
    "\n",
    "march = \"data/processed/bdm/2024-03.csv\"\n",
    "with open(march, \"r\", encoding=\"utf-8\") as file:\n",
    "    df_march = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Preprocessing --------------------\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "# Load spaCy Portuguese model once\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "# Dictionary for acronym expansion\n",
    "acronyms = {\n",
    "    \"Selic\": \"Sistema Especial de Liquidação e de Custódia\",\n",
    "    \"PIB\": \"Produto Interno Bruto\",\n",
    "    \"CDI\": \"Certificado de Depósito Interbancário\",\n",
    "    \"LPRs\": \"Loan Prime Rates\",\n",
    "    \"Ibovespa\": \"Índice Bovespa\",\n",
    "    \"BB\": \"Banco do Brasil\",\n",
    "    \"BC\": \"Banco Central\",\n",
    "    \"FGTS\": \"Fundo de Garantia do Tempo de Serviço\",\n",
    "    \"STF\": \"Supremo Tribunal Federal\",\n",
    "    \"CPI\": \"Índice de Preços ao Consumidor\",\n",
    "    \"MP\": \"Medida Provisória\",\n",
    "    \"EUA\": \"Estados Unidos\",\n",
    "    \"ONU\": \"Organização das Nações Unidas\",\n",
    "    \"FGV\": \"Fundação Getúlio Vargas\",\n",
    "    \"IBGE\": \"Instituto Brasileiro de Geografia e Estatística\",\n",
    "    \"BNDES\": \"Banco Nacional de Desenvolvimento Econômico e Social\",\n",
    "    \"IPCA\": \"Índice Nacional de Preços ao Consumidor Amplo\",\n",
    "    \"DI\": \"Depósito Interfinanceiro\",\n",
    "    \"IR\": \"Imposto de Renda\",\n",
    "    \"OI\": \"Operadora Oi\",\n",
    "    \"CV\": \"Câmara de Vereadores\"\n",
    "}\n",
    "\n",
    "# Noisy acronyms to remove\n",
    "noisy_acronyms = {\"ROMI\", \"ENEVA\", \"LIGHT\", \"DA\"}\n",
    "\n",
    "def normalize_numbers(text):\n",
    "    text = re.sub(r\"R\\$ ?([\\d.,]+) bilhões\", r\"\\1B\", text)\n",
    "    text = re.sub(r\"R\\$ ?([\\d.,]+) milhões\", r\"\\1M\", text)\n",
    "    text = re.sub(r\"([\\d.,]+) pp\", r\"\\1%\", text)\n",
    "    text = text.replace(\",\", \"\")\n",
    "    return text\n",
    "\n",
    "def expand_acronyms(text, acronym_dict):\n",
    "    for acronym, full_form in acronym_dict.items():\n",
    "        text = re.sub(rf'\\b{re.escape(acronym)}\\b', full_form, text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "def remove_noisy_acronyms(text, noisy_set):\n",
    "    return re.sub(r'\\b(?:' + '|'.join(noisy_set) + r')\\b', '', text)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_stop and token.is_alpha])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = normalize_numbers(text)\n",
    "    text = expand_acronyms(text, acronyms)\n",
    "    text = remove_noisy_acronyms(text, noisy_acronyms)\n",
    "    text = lemmatize_text(text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to the dataset\n",
    "df_jan['cleaned_article'] = df_jan['article'].apply(preprocess_text)\n",
    "df_feb['cleaned_article'] = df_feb['article'].apply(preprocess_text)\n",
    "df_march['cleaned_article'] = df_march['article'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_jan['label'].value_counts())\n",
    "sns.countplot(x='label', data=df_jan)\n",
    "plt.title('Label Distribution in January Dataset')\n",
    "plt.savefig(\"results/bert_embeddings_experiment_v1/figures/label_distribution_january.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_feb['label'].value_counts())\n",
    "sns.countplot(x='label', data=df_feb)\n",
    "plt.title('Label Distribution in February Dataset')\n",
    "plt.savefig(\"results/bert_embeddings_experiment_v1/figures/label_distribution_february.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_march['label'].value_counts())\n",
    "sns.countplot(x='label', data=df_march)\n",
    "plt.title('Label Distribution in March Dataset')\n",
    "plt.savefig(\"results/bert_embeddings_experiment_v1/figures/label_distribution_march.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate BERT Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERTimbau tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "model = AutoModel.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding(text, tokenizer, model):\n",
    "    # tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "\n",
    "    # pass inputs through model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Extract [CLS] token embedding (shape: [batch_size, hidden_size])\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]  # [CLS] token is the first token\n",
    "    return cls_embedding.squeeze(0).numpy()  # convert to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jan['embedding'] = df_jan['cleaned_article'].apply(lambda x: np.array(get_bert_embedding(x, tokenizer, model)))\n",
    "df_feb['embedding'] = df_feb['cleaned_article'].apply(lambda x: np.array(get_bert_embedding(x, tokenizer, model)))\n",
    "df_march['embedding'] = df_march['cleaned_article'].apply(lambda x: np.array(get_bert_embedding(x, tokenizer, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classification\n",
    "- train on January/February corpus\n",
    "- test on March corpus\n",
    "- repeated for both with and without neutral classifications (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine January and February data for training\n",
    "df_train_multi = pd.concat([df_jan, df_feb])\n",
    "X_train_multi = np.vstack(df_train_multi['embedding'].values)\n",
    "y_train_multi = df_train_multi['label']\n",
    "\n",
    "# multi classification and test on march\n",
    "X_test_multi = np.vstack(df_march['embedding'].values)\n",
    "y_test_multi = df_march['label']\n",
    "\n",
    "# binary Classification and test on march\n",
    "df_train_binary = df_train_multi[df_train_multi['label'] != 0]\n",
    "df_march_binary = df_march[df_march['label'] != 0]\n",
    "\n",
    "X_train_binary = np.vstack(df_train_binary['embedding'].values)\n",
    "y_train_binary = df_train_binary['label']\n",
    "\n",
    "X_test_binary = np.vstack(df_march_binary['embedding'].values)\n",
    "y_test_binary = df_march_binary['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multi-class classifier\n",
    "multi_clf = LogisticRegression(max_iter=1000)\n",
    "multi_clf.fit(X_train_multi, y_train_multi)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_multi = multi_clf.predict(X_test_multi)\n",
    "print(\"Multi-Class Report:\\n\", classification_report(y_test_multi, y_pred_multi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train binary classifier\n",
    "binary_clf = LogisticRegression(max_iter=1000)\n",
    "binary_clf.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_binary = binary_clf.predict(X_test_binary)\n",
    "print(\"Binary Classification Report:\\n\", classification_report(y_test_binary, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"results/bert_embeddings_experiment_v1/metrics\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "cm_multi = confusion_matrix(y_test_multi, y_pred_multi)\n",
    "class_report = classification_report(y_test_multi, y_pred_multi, target_names=[\"-1\", \"0\", \"1\"])\n",
    "\n",
    "report_path = os.path.join(results_dir, \"classification_report_multi.txt\")\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(class_report)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_multi, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=[\"-1\", \"0\", \"1\"], yticklabels=[\"-1\", \"0\", \"1\"])\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Multi-Class Confusion Matrix\")\n",
    "\n",
    "conf_matrix_path = os.path.join(results_dir, \"confusion_matrix_multi.png\")\n",
    "plt.savefig(conf_matrix_path)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Classification report saved to: {report_path}\")\n",
    "print(f\"Confusion matrix saved to: {conf_matrix_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_binary = confusion_matrix(y_test_binary, y_pred_binary)\n",
    "class_report_binary = classification_report(y_test_binary, y_pred_binary, target_names=[\"-1\", \"1\"])\n",
    "\n",
    "report_path_binary = os.path.join(results_dir, \"classification_report_binary.txt\")\n",
    "with open(report_path_binary, \"w\") as f:\n",
    "    f.write(\"Classification Report (Binary):\\n\")\n",
    "    f.write(class_report_binary)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_binary, annot=True, fmt=\"d\", cmap=\"Greens\", \n",
    "            xticklabels=[\"-1\", \"1\"], yticklabels=[\"-1\", \"1\"])\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Binary Confusion Matrix\")\n",
    "\n",
    "conf_matrix_path_binary = os.path.join(results_dir, \"confusion_matrix_binary.png\")\n",
    "plt.savefig(conf_matrix_path_binary)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Binary classification report saved to: {report_path_binary}\")\n",
    "print(f\"Binary confusion matrix saved to: {conf_matrix_path_binary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miss-classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add multi-class predictions to df_march\n",
    "df_march['classification_multi'] = y_pred_multi\n",
    "\n",
    "# Add binary predictions to df_march_binary\n",
    "df_march_binary['classification_binary'] = y_pred_binary\n",
    "\n",
    "# Create a DataFrame containing the articles, labels, and classifications\n",
    "df_combined_classifications = df_march[[\"cleaned_article\", 'label', 'classification_multi']].copy()\n",
    "if not df_march_binary.empty:\n",
    "    # Add binary classifications for binary-labeled articles\n",
    "    df_combined_classifications['classification_binary'] = np.nan\n",
    "    df_combined_classifications.loc[\n",
    "        df_combined_classifications.index.isin(df_march_binary.index), 'classification_binary'\n",
    "    ] = df_march_binary['classification_binary']\n",
    "\n",
    "# Save the results to a CSV file\n",
    "output_path = \"results/bert_embeddings_experiment_v1/metrics/articles-with-misclassified-multi.csv\"\n",
    "df_combined_classifications.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the resulting DataFrame for review\n",
    "df_combined_classifications\n",
    "\n",
    "print(f\"Articles with classifications have been saved to {output_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for multi-class misclassifications\n",
    "df_misclassified_multi = df_march[df_march['classification_multi'] != df_march['label']][\n",
    "    ['cleaned_article', 'label', 'classification_multi']\n",
    "]\n",
    "\n",
    "df_misclassified_multi['misclassification_type'] = df_misclassified_multi.apply(\n",
    "    lambda row: f\"{row['label']} misclassified as {row['classification_multi']}\", axis=1\n",
    ")\n",
    "\n",
    "# totals for each misclassification type (multi-class)\n",
    "multi_counts = df_misclassified_multi['misclassification_type'].value_counts()\n",
    "misclassified_multi_path = \"results/bert_embeddings_experiment_v1/metrics/misclassified-multi.csv\"\n",
    "df_misclassified_multi.to_csv(misclassified_multi_path, index=False)\n",
    "\n",
    "print(\"Multi-Class Misclassification Totals:\")\n",
    "print(multi_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for binary misclassifications\n",
    "df_misclassified_binary = df_march_binary[df_march_binary['classification_binary'] != df_march_binary['label']][\n",
    "    ['cleaned_article', 'label', 'classification_binary']\n",
    "]\n",
    "\n",
    "df_misclassified_binary['misclassification_type'] = df_misclassified_binary.apply(\n",
    "    lambda row: f\"{row['label']} misclassified as {row['classification_binary']}\", axis=1\n",
    ")\n",
    "\n",
    "# totals for each misclassification type (binary)\n",
    "binary_counts = df_misclassified_binary['misclassification_type'].value_counts()\n",
    "misclassified_binary_path = \"results/bert_embeddings_experiment_v1/metrics/misclassified-binary.csv\"\n",
    "df_misclassified_binary.to_csv(misclassified_binary_path, index=False)\n",
    "\n",
    "print(\"Binary Misclassification Totals:\")\n",
    "print(binary_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
