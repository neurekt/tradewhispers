{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27ebcb71",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef481ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d66539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>HEADING</th>\n",
       "      <th>ARTICLE CONTENT</th>\n",
       "      <th>COMMENTS</th>\n",
       "      <th>USD/BRL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-21 14:34:00</td>\n",
       "      <td>BC: Fluxo cambial total na semana passada (11 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fluxo cambial negativo significa menos reserva...</td>\n",
       "      <td>5.8177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-21 14:34:00</td>\n",
       "      <td>Fluxo total em novembro, até dia 14, está nega...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fluxo cambial negativo significa menos reserva...</td>\n",
       "      <td>5.8177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-21 14:35:00</td>\n",
       "      <td>Itaú BBA mantém recomendação de compra para Di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Notícias do mercado de ações não afetam a taxa...</td>\n",
       "      <td>5.8206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-21 14:35:00</td>\n",
       "      <td>Banco destaca que desempenho da empresa segue ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Notícias do mercado de ações não afetam a taxa...</td>\n",
       "      <td>5.8206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-21 14:36:00</td>\n",
       "      <td>Fed/Goolsbee: Juros devem se aproximar do níve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O FED anuncia que a taxa de equilíbrio da econ...</td>\n",
       "      <td>5.8192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Timestamp                                            HEADING  \\\n",
       "0  2024-11-21 14:34:00  BC: Fluxo cambial total na semana passada (11 ...   \n",
       "1  2024-11-21 14:34:00  Fluxo total em novembro, até dia 14, está nega...   \n",
       "2  2024-11-21 14:35:00  Itaú BBA mantém recomendação de compra para Di...   \n",
       "3  2024-11-21 14:35:00  Banco destaca que desempenho da empresa segue ...   \n",
       "4  2024-11-21 14:36:00  Fed/Goolsbee: Juros devem se aproximar do níve...   \n",
       "\n",
       "  ARTICLE CONTENT                                           COMMENTS  USD/BRL  \n",
       "0             NaN  Fluxo cambial negativo significa menos reserva...   5.8177  \n",
       "1             NaN  Fluxo cambial negativo significa menos reserva...   5.8177  \n",
       "2             NaN  Notícias do mercado de ações não afetam a taxa...   5.8206  \n",
       "3             NaN  Notícias do mercado de ações não afetam a taxa...   5.8206  \n",
       "4             NaN  O FED anuncia que a taxa de equilíbrio da econ...   5.8192  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exchange rate dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>USD/BRL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-02T09:00:00</td>\n",
       "      <td>5.6379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-02T09:01:00</td>\n",
       "      <td>5.6340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-02T09:02:00</td>\n",
       "      <td>5.6277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-02T09:03:00</td>\n",
       "      <td>5.6238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-02T09:04:00</td>\n",
       "      <td>5.6189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Timestamp  USD/BRL\n",
       "0  2024-09-02T09:00:00   5.6379\n",
       "1  2024-09-02T09:01:00   5.6340\n",
       "2  2024-09-02T09:02:00   5.6277\n",
       "3  2024-09-02T09:03:00   5.6238\n",
       "4  2024-09-02T09:04:00   5.6189"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "news_df = pd.read_csv('../data/interim/bdm-corpus-2/stage-0.csv')\n",
    "fx_df = pd.read_csv('../data/interim/usd-brl.csv')\n",
    "\n",
    "# preview\n",
    "print('News dataset:')\n",
    "display(news_df.head())\n",
    "print('Exchange rate dataset:')\n",
    "display(fx_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a217a0",
   "metadata": {},
   "source": [
    "## Headline EDA\n",
    "### Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: This bar chart displays the 20 most frequent tokens found in the headlines, with common stopwords removed.\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "stop_words = set(stopwords.words('portuguese')) | set(stopwords.words('english')) #checks for stop words in both languages\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.findall(r'\\b\\w+\\b', str(text).lower()) # lowercase and remove punctuation\n",
    "    return [t for t in tokens if t not in stop_words and len(t) > 1] # filter out stopwords and single-character tokens\n",
    "\n",
    "all_tokens = []\n",
    "for headline in news_df['HEADING'].dropna():\n",
    "    all_tokens.extend(tokenize(headline)) \n",
    "\n",
    "token_counts = Counter(all_tokens)\n",
    "top_tokens = token_counts.most_common(20)\n",
    "\n",
    "tokens, counts = zip(*top_tokens)\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=list(tokens), y=list(counts), palette='viridis')\n",
    "plt.title('Top 20 Most Common Tokens in Headlines')\n",
    "plt.xlabel('Token')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef00d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: distribution of the number of tokens per headline in the dataset\n",
    "headline_lengths = [len(tokenize(h)) for h in news_df['HEADING'].dropna()]\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(headline_lengths, bins=30)\n",
    "plt.title('Distribution of Headline Lengths (in Tokens)')\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca51538",
   "metadata": {},
   "source": [
    "### Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca182f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table: sample of headlines along with their timestamps and source outlets to show the type of financial news and metadata coverage\n",
    "example_cols = ['Timestamp', 'HEADING']\n",
    "if 'SOURCE' in news_df.columns:\n",
    "    example_cols.append('SOURCE')\n",
    "display(news_df[example_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ebfe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table: summary stats of headline length - mean, median, and std of token counts in headlines\n",
    "headline_lengths = [len(tokenize(h)) for h in news_df['HEADING'].dropna()]\n",
    "import statistics\n",
    "summary = {\n",
    "    'Mean': np.mean(headline_lengths),\n",
    "    'Median': np.median(headline_lengths),\n",
    "    'Std': np.std(headline_lengths)\n",
    "}\n",
    "display(pd.DataFrame([summary]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf9100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table: number of headlines and total token count per day, useful for computing daily lexical density and monitoring coverage gaps\n",
    "news_df['date'] = pd.to_datetime(news_df['Timestamp']).dt.date\n",
    "daily_headlines = news_df.groupby('date')['HEADING'].count()\n",
    "daily_tokens = news_df.groupby('date')['HEADING'].apply(lambda x: sum(len(tokenize(h)) for h in x))\n",
    "daily_stats = pd.DataFrame({'headline_count': daily_headlines, 'token_count': daily_tokens})\n",
    "display(daily_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac80a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table: News density by hour-of-day - average frequency of headlines per hour, computed across all days\n",
    "news_df['hour_of_day'] = pd.to_datetime(news_df['Timestamp']).dt.date\n",
    "hourly_density = news_df.groupby('hour_of_day').size().div(news_df['date'].nunique())\n",
    "display(hourly_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b215879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table: 20 days with the most headlines\n",
    "news_df['date'] = pd.to_datetime(news_df['Timestamp']).dt.date\n",
    "daily_counts = news_df.groupby('date').size().sort_values(ascending=False)\n",
    "top20_days = daily_counts.head(20).reset_index()\n",
    "top20_days.columns = ['Date', 'Headline Count']\n",
    "display(top20_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e5676b",
   "metadata": {},
   "source": [
    "## Article Content EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd285c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table: summary stats of article content length - summarizes the word/token count distribution for full-text articles, if the data is available (the rows that have it).\n",
    "if 'ARTICLE CONTENT' in news_df.columns:\n",
    "    article_lengths = [len(tokenize(a)) for a in news_df['ARTICLE CONTENT'].dropna()]\n",
    "    if article_lengths:\n",
    "        summary = {\n",
    "            'Mean': np.mean(article_lengths),\n",
    "            'Median': np.median(article_lengths),\n",
    "            'Std': np.std(article_lengths)\n",
    "        }\n",
    "        display(pd.DataFrame([summary]))\n",
    "    else:\n",
    "        print('No article content available.')\n",
    "else:\n",
    "    print('ARTICLE CONTENT column not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d268377",
   "metadata": {},
   "source": [
    "## Exchange Rate Data EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8384cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: Daily average exchange rate volatility\n",
    "# this line chart shows how the volatility of the USD/BRL exchange rate changes over time, computed as the standard deviation of minute-level returns within each day.\n",
    "fx_df['Timestamp'] = pd.to_datetime(fx_df['Timestamp'])\n",
    "fx_df = fx_df.sort_values('Timestamp')\n",
    "fx_df['return'] = fx_df['USD/BRL'].pct_change()\n",
    "fx_df['date'] = fx_df['Timestamp'].dt.date\n",
    "volatility = fx_df.groupby('date')['return'].std()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "volatility.plot()\n",
    "plt.title('Daily Average Exchange Rate Volatility (USD/BRL)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volatility (Std of 1-min returns)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b102ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table: Graph of USD/BRL exchange rate over all beginning and ending timestamp\n",
    "fx_df['date'] = pd.to_datetime(fx_df['Timestamp']).dt.date\n",
    "plt.figure(figsize=(12,6))\n",
    "fx_df.groupby('date')['USD/BRL'].mean().plot()\n",
    "plt.title('USD/BRL Exchange Rate Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Exchange Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e25bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table: Find 20 days with the highest FX volatility\n",
    "fx_df['return'] = fx_df['USD/BRL'].pct_change()\n",
    "fx_df['date'] = pd.to_datetime(fx_df['Timestamp']).dt.date\n",
    "volatility_by_day = fx_df.groupby('date')['return'].std()\n",
    "top20_vol_days = volatility_by_day.sort_values(ascending=False).head(20).reset_index()\n",
    "top20_vol_days.columns = ['Date', 'Volatility']\n",
    "display(top20_vol_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5001b45",
   "metadata": {},
   "source": [
    "## Forward Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d3ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count -1</th>\n",
       "      <th>Count 0</th>\n",
       "      <th>Count 1</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Forward Return t+1</th>\n",
       "      <td>1712</td>\n",
       "      <td>123</td>\n",
       "      <td>1684</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+2</th>\n",
       "      <td>1735</td>\n",
       "      <td>58</td>\n",
       "      <td>1726</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+3</th>\n",
       "      <td>1730</td>\n",
       "      <td>79</td>\n",
       "      <td>1710</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+4</th>\n",
       "      <td>1717</td>\n",
       "      <td>86</td>\n",
       "      <td>1716</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+5</th>\n",
       "      <td>1682</td>\n",
       "      <td>54</td>\n",
       "      <td>1783</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+6</th>\n",
       "      <td>1625</td>\n",
       "      <td>46</td>\n",
       "      <td>1848</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+7</th>\n",
       "      <td>1641</td>\n",
       "      <td>58</td>\n",
       "      <td>1820</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+8</th>\n",
       "      <td>1636</td>\n",
       "      <td>51</td>\n",
       "      <td>1832</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+9</th>\n",
       "      <td>1613</td>\n",
       "      <td>58</td>\n",
       "      <td>1848</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+10</th>\n",
       "      <td>1596</td>\n",
       "      <td>34</td>\n",
       "      <td>1889</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+11</th>\n",
       "      <td>1592</td>\n",
       "      <td>42</td>\n",
       "      <td>1885</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+12</th>\n",
       "      <td>1555</td>\n",
       "      <td>45</td>\n",
       "      <td>1919</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+13</th>\n",
       "      <td>1531</td>\n",
       "      <td>59</td>\n",
       "      <td>1929</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+14</th>\n",
       "      <td>1533</td>\n",
       "      <td>41</td>\n",
       "      <td>1945</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+15</th>\n",
       "      <td>1519</td>\n",
       "      <td>43</td>\n",
       "      <td>1957</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+16</th>\n",
       "      <td>1511</td>\n",
       "      <td>45</td>\n",
       "      <td>1963</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+17</th>\n",
       "      <td>1504</td>\n",
       "      <td>38</td>\n",
       "      <td>1977</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+18</th>\n",
       "      <td>1509</td>\n",
       "      <td>48</td>\n",
       "      <td>1962</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+19</th>\n",
       "      <td>1495</td>\n",
       "      <td>38</td>\n",
       "      <td>1986</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forward Return t+20</th>\n",
       "      <td>1488</td>\n",
       "      <td>43</td>\n",
       "      <td>1988</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Count -1  Count 0  Count 1  Total\n",
       "Forward Return t+1       1712      123     1684   3519\n",
       "Forward Return t+2       1735       58     1726   3519\n",
       "Forward Return t+3       1730       79     1710   3519\n",
       "Forward Return t+4       1717       86     1716   3519\n",
       "Forward Return t+5       1682       54     1783   3519\n",
       "Forward Return t+6       1625       46     1848   3519\n",
       "Forward Return t+7       1641       58     1820   3519\n",
       "Forward Return t+8       1636       51     1832   3519\n",
       "Forward Return t+9       1613       58     1848   3519\n",
       "Forward Return t+10      1596       34     1889   3519\n",
       "Forward Return t+11      1592       42     1885   3519\n",
       "Forward Return t+12      1555       45     1919   3519\n",
       "Forward Return t+13      1531       59     1929   3519\n",
       "Forward Return t+14      1533       41     1945   3519\n",
       "Forward Return t+15      1519       43     1957   3519\n",
       "Forward Return t+16      1511       45     1963   3519\n",
       "Forward Return t+17      1504       38     1977   3519\n",
       "Forward Return t+18      1509       48     1962   3519\n",
       "Forward Return t+19      1495       38     1986   3519\n",
       "Forward Return t+20      1488       43     1988   3519"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/interim/bdm-corpus-2/stage-1.csv\")\n",
    "\n",
    "# relevant columns\n",
    "forward_return_columns = [f\"Forward Return t+{i}\" for i in range(1, 21)]\n",
    "\n",
    "# Count the values -1, 0, and 1 in each column\n",
    "value_counts = {}\n",
    "for col in forward_return_columns:\n",
    "    counts = df[col].value_counts().reindex([-1, 0, 1], fill_value=0)\n",
    "    value_counts[col] = counts\n",
    "\n",
    "counts_df = pd.DataFrame(value_counts).T\n",
    "counts_df.columns = ['Count -1', 'Count 0', 'Count 1']\n",
    "counts_df['Total'] = counts_df.sum(axis=1)\n",
    "\n",
    "display(counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a7722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direção\n",
      "Aumento       1783\n",
      "Diminuição    1682\n",
      "Name: count, dtype: int64\n",
      "Total: 3465\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/interim/bdm-corpus-2/stage-2.csv\")\n",
    "counts = df[\"Direção\"].value_counts()\n",
    "print(counts)\n",
    "print(f\"Total: {counts.sum()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
